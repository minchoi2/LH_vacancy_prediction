{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn_3QwFx_yor",
        "outputId": "b0ad5b13-c7ff-4c1c-925a-ca9b9eb98777"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pycaret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pfAmXZ07A_JS",
        "outputId": "3efcf5ed-cd98-4157-b817-033d7f2e35a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycaret\n",
            "  Downloading pycaret-3.3.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.11/dist-packages (from pycaret) (7.7.1)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (4.67.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.26.4)\n",
            "Collecting pandas<2.2.0 (from pycaret)\n",
            "  Downloading pandas-2.1.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.1.5)\n",
            "Collecting scipy<=1.11.4,>=1.6.1 (from pycaret)\n",
            "  Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib<1.4,>=1.2.0 (from pycaret)\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: scikit-learn>1.4.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.6.1)\n",
            "Collecting pyod>=1.1.3 (from pycaret)\n",
            "  Downloading pyod-2.0.3.tar.gz (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.6/169.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.13.0)\n",
            "Collecting category-encoders>=2.4.0 (from pycaret)\n",
            "  Downloading category_encoders-2.8.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (4.5.0)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.61.0)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (2.32.3)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (5.9.5)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (8.6.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (5.10.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.1.1)\n",
            "Collecting deprecation>=2.1.0 (from pycaret)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting xxhash (from pycaret)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting matplotlib<3.8.0 (from pycaret)\n",
            "  Downloading matplotlib-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting scikit-plot>=0.3.7 (from pycaret)\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.5)\n",
            "Requirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (5.24.1)\n",
            "Collecting kaleido>=0.2.1 (from pycaret)\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "Collecting schemdraw==0.15 (from pycaret)\n",
            "  Downloading schemdraw-0.15-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting plotly-resampler>=0.8.3.1 (from pycaret)\n",
            "  Downloading plotly_resampler-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.14.4)\n",
            "Collecting sktime==0.26.0 (from pycaret)\n",
            "  Downloading sktime-0.26.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting tbats>=1.1.3 (from pycaret)\n",
            "  Downloading tbats-1.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting pmdarima>=2.0.4 (from pycaret)\n",
            "  Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
            "Collecting wurlitzer (from pycaret)\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from sktime==0.26.0->pycaret) (24.2)\n",
            "Collecting scikit-base<0.8.0 (from sktime==0.26.0->pycaret)\n",
            "  Downloading scikit_base-0.7.8-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting scikit-learn>1.4.0 (from pycaret)\n",
            "  Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category-encoders>=2.4.0->pycaret) (1.0.1)\n",
            "INFO: pip is looking at multiple versions of category-encoders to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting category-encoders>=2.4.0 (from pycaret)\n",
            "  Downloading category_encoders-2.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (0.1.3)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (3.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.12.0->pycaret) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.5.0->pycaret)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret) (1.4.8)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret) (5.7.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.55.0->pycaret) (0.44.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0->pycaret) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0->pycaret) (2025.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.14.0->pycaret) (9.0.0)\n",
            "Collecting dash>=2.9.0 (from plotly-resampler>=0.8.3.1->pycaret)\n",
            "  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.10.15)\n",
            "Collecting tsdownsample>=0.1.3 (from plotly-resampler>=0.8.3.1->pycaret)\n",
            "  Downloading tsdownsample-0.1.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=2.0.4->pycaret) (3.0.11)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=2.0.4->pycaret) (2.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->pycaret) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->pycaret) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->pycaret) (2025.1.31)\n",
            "Collecting Flask<3.1,>=1.0.4 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting Werkzeug<3.1 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting dash-html-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-table==5.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (4.12.2)\n",
            "Collecting retrying (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.22.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret) (4.3.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<3.8.0->pycaret) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.5)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.9.0)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.2.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (3.1.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.4.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.1)\n",
            "Downloading pycaret-3.3.2-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.1/486.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schemdraw-0.15-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sktime-0.26.0-py3-none-any.whl (21.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading category_encoders-2.7.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.1.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly_resampler-0.10.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tbats-1.1.3-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_base-0.7.8-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.1/130.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tsdownsample-0.1.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-2.0.3-py3-none-any.whl size=200466 sha256=553b93cb3bf84b6e5b9c0722e6792fe5cb8b948b76602a696616dfa26c1cdb15\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/60/5b/f74eccd2c9c892a2c298202ca510f10995f9940647fcc2d97f\n",
            "Successfully built pyod\n",
            "Installing collected packages: kaleido, dash-table, dash-html-components, dash-core-components, xxhash, wurlitzer, Werkzeug, tsdownsample, scipy, scikit-base, schemdraw, retrying, joblib, jedi, deprecation, scikit-learn, pandas, matplotlib, Flask, sktime, scikit-plot, pyod, dash, pmdarima, plotly-resampler, category-encoders, tbats, pycaret\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 3.1.0\n",
            "    Uninstalling Flask-3.1.0:\n",
            "      Successfully uninstalled Flask-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Flask-3.0.3 Werkzeug-3.0.6 category-encoders-2.7.0 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 deprecation-2.1.0 jedi-0.19.2 joblib-1.3.2 kaleido-0.2.1 matplotlib-3.7.5 pandas-2.1.4 plotly-resampler-0.10.0 pmdarima-2.0.4 pycaret-3.3.2 pyod-2.0.3 retrying-1.3.4 schemdraw-0.15 scikit-base-0.7.8 scikit-learn-1.4.2 scikit-plot-0.3.7 scipy-1.11.4 sktime-0.26.0 tbats-1.1.3 tsdownsample-0.1.4.1 wurlitzer-3.1.1 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "f7ce6aed34b9461f82258b28ac0eb615"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.regression import *"
      ],
      "metadata": {
        "id": "mhYp4dlA_yms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2WNsHm14SnE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "# Library Settings\n",
        "mpl.rcParams['font.family'] = 'Malgun Gothic'  # 윈도우에서 사용되는 한글 폰트\n",
        "mpl.rcParams['axes.unicode_minus'] = False  # 마이너스 기호가 깨지지 않도록 설정"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoCV, RidgeCV, LarsCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def split_data(my_data):\n",
        "    \"\"\"데이터를 학습 및 검증 세트로 나누는 함수\"\"\"\n",
        "    for df_index in list(itertools.combinations(my_data['Year'].unique(), 2)):\n",
        "        val_df_index = list(df_index)\n",
        "        train_df_index = list(set(my_data['Year'].values) - set(val_df_index))\n",
        "        val = my_data[my_data['Year'].isin(val_df_index)]\n",
        "        train = my_data[my_data['Year'].isin(train_df_index)]\n",
        "        yield val, train\n",
        "\n",
        "def get_feature_importance(x, y, random_state=42,top_k=10):\n",
        "    \"\"\"\n",
        "    다양한 모델(Lasso, Ridge, LARS, RandomForest)을 사용해 Feature Importance를 계산하고\n",
        "    공통적으로 중요한 피처를 반환하는 함수입니다.\n",
        "\n",
        "    Parameters:\n",
        "        X (pd.DataFrame): 독립 변수 데이터프레임\n",
        "        y (pd.Series): 종속 변수 (타겟)\n",
        "        random_state (int): 난수 시드\n",
        "\n",
        "    Returns:\n",
        "        selected_features (list): 공통적으로 중요한 피처 목록\n",
        "    \"\"\"\n",
        "    # 피처 목록\n",
        "    feature_lists = []\n",
        "\n",
        "    # 1. Lasso 모델\n",
        "    lasso = LassoCV(cv=5, random_state=random_state).fit(x, y)\n",
        "    lasso_importance = np.abs(lasso.coef_)\n",
        "    lasso_features = x.columns[lasso_importance > 0].tolist()\n",
        "    feature_lists.extend(lasso_features)\n",
        "    print(\"Lasso Selected Features:\", lasso_features)\n",
        "\n",
        "    # 2. Ridge 모델\n",
        "    ridge = RidgeCV(cv=5).fit(x, y)\n",
        "    ridge_importance = np.abs(ridge.coef_)\n",
        "    ridge_features = x.columns[ridge_importance > np.mean(ridge_importance)].tolist()\n",
        "    feature_lists.extend(ridge_features)\n",
        "    print(\"Ridge Selected Features:\", ridge_features)\n",
        "\n",
        "    # 3. LARS 모델\n",
        "    lars = LarsCV(cv=5).fit(x, y)\n",
        "    lars_importance = np.abs(lars.coef_)\n",
        "    lars_features = x.columns[lars_importance > 0].tolist()\n",
        "    feature_lists.extend(lars_features)\n",
        "    print(\"LARS Selected Features:\", lars_features)\n",
        "\n",
        "    # 피처 등장 횟수 계산\n",
        "    feature_counts = Counter(feature_lists)\n",
        "\n",
        "    # 세 가지 이상 모델에서 등장한 피처만 선택\n",
        "    common_features = [feature for feature, count in feature_counts.items() if count >= 2][:top_k]\n",
        "\n",
        "    return common_features\n",
        "\n",
        "def scale_data(data, type = \"ss\", scaler=None, is_fit=True):\n",
        "    if is_fit:\n",
        "        \"\"\"스케일링 함수 선정\"\"\"\n",
        "        if type == \"ss\":\n",
        "            scaler = StandardScaler()\n",
        "        elif type == \"ms\":\n",
        "            scaler = MinMaxScaler()\n",
        "        elif type == \"rs\":\n",
        "            scaler = RobustScaler()\n",
        "        else:\n",
        "            print(\"Wrong Name of Scaler\")\n",
        "        X_scaled = scaler.fit_transform(data)\n",
        "    else:\n",
        "        scaler = scaler\n",
        "        X_scaled = scaler.transform(data)\n",
        "\n",
        "    # 스케일링된 데이터를 DataFrame으로 변환\n",
        "    X_scaled_df = pd.DataFrame(X_scaled, columns=data.columns)\n",
        "\n",
        "    return X_scaled_df, scaler\n",
        "\n",
        "def prepare_data_for_prediction(data_seen, data_unseen):\n",
        "    \"\"\"\n",
        "    주어진 데이터를 전처리하여 NaN을 제거하고, 예측에 사용할 데이터 준비.\n",
        "    \"\"\"\n",
        "    test_data_1 = pd.DataFrame(data_unseen.loc[TEST_YEARS[0]]).T\n",
        "    test_data_2 = pd.DataFrame(data_unseen.loc[TEST_YEARS[1]]).T\n",
        "    #test_data_3 = pd.DataFrame(data_unseen.loc[TEST_YEARS[2]]).T\n",
        "    data_2023 = pd.DataFrame(data_unseen.loc[2023]).T\n",
        "\n",
        "    # NaN 제거\n",
        "    test_data_1.drop(data_seen.columns[data_seen.isna().any()], axis=1, inplace=True)\n",
        "    test_data_2.drop(data_seen.columns[data_seen.isna().any()], axis=1, inplace=True)\n",
        "    #test_data_3.drop(data_seen.columns[data_seen.isna().any()], axis=1, inplace=True)\n",
        "    data_2023.drop(data_seen.columns[data_seen.isna().any()], axis=1, inplace=True)\n",
        "\n",
        "    data_unseen = data_unseen.drop(data_seen.columns[data_seen.isna().any()], axis=1)\n",
        "    data_seen = data_seen.drop(data_seen.columns[data_seen.isna().any()], axis=1)\n",
        "\n",
        "    data_seen.to_csv(f\"data_seen_{CROP}{MODEL_NUM}.csv\",encoding='utf-8-sig',index=None)\n",
        "    data_unseen.to_csv(f\"data_unseen_{CROP}{MODEL_NUM}.csv\",encoding='utf-8-sig',index=None)\n",
        "    data_2023.to_csv(f\"data_2023_{CROP}{MODEL_NUM}.csv\",encoding='utf-8-sig',index=None)\n",
        "\n",
        "    return data_seen, data_unseen, test_data_1, test_data_2, data_2023 # test_data_3\n",
        "\n",
        "def calculate_error_rate(actual, predicted):\n",
        "    \"\"\"평균 절대 오차율 계산\"\"\"\n",
        "    return 100 * mean_absolute_error(actual, predicted) / np.mean(actual)\n",
        "\n",
        "\n",
        "def create_voting_regressor(base_models_params, random_seed=None):\n",
        "    estimators = []\n",
        "    for name, model in base_models_params:\n",
        "        if hasattr(model, 'random_state') and model.random_state is None:\n",
        "            model.random_state = random_seed  # 랜덤 시드 설정\n",
        "        estimators.append((name, model))  # VotingRegressor에 필요한 형식\n",
        "    return VotingRegressor(estimators=estimators)\n",
        "\n",
        "def train_and_predict(model, train_data, val_data, test_data, target_col):\n",
        "    \"\"\"모델 학습 및 예측\"\"\"\n",
        "    # 모델의 `estimators` 속성을 확인\n",
        "    if hasattr(model, 'estimators') and (not model.estimators or not isinstance(model.estimators, list)):\n",
        "        raise ValueError(\"The 'estimators' attribute of the model is invalid. It should be a non-empty list of (string, estimator) tuples.\")\n",
        "\n",
        "    model.fit(train_data.drop(columns=[target_col, 'Year']), train_data[target_col])\n",
        "    predictions_train = model.predict(train_data.drop(columns=[target_col, 'Year']))\n",
        "    predictions_val = model.predict(val_data.drop(columns=[target_col, 'Year']))\n",
        "    predictions_test = model.predict(test_data.drop(columns=[target_col, 'Year']))\n",
        "    return predictions_train, predictions_val, predictions_test\n",
        "\n",
        "def analyze_results(result_df, test_years, top_k=3):\n",
        "    result_df['val_years_str'] = result_df['val_years'].astype(str)\n",
        "\n",
        "    \"\"\"결과 데이터프레임을 분석하여 최종 평균값 계산\"\"\"\n",
        "    grouped_results = (\n",
        "        result_df.groupby(\"val_years_str\", group_keys=False)\n",
        "        .apply(lambda x: x.nsmallest(top_k, \"val\"))\n",
        "    )\n",
        "    return {\n",
        "        \"train\": grouped_results[\"train\"].mean(),\n",
        "        \"val\": grouped_results[\"val\"].mean(),\n",
        "        f\"final_preds_{test_years[0]}\": grouped_results[f\"test_preds_{test_years[0]}\"].mean(),\n",
        "        f\"final_preds_{test_years[1]}\": grouped_results[f\"test_preds_{test_years[1]}\"].mean(),\n",
        "        f\"final_preds_{LIVE_YEAR}\": grouped_results[f\"live_preds_{LIVE_YEAR}\"].mean(),\n",
        "        \"live_err\": grouped_results[\"live_err\"].mean(),\n",
        "    }\n",
        "\n",
        "def train_and_optimize_models(data_seen, model_num = 20, top_k = None, my_model_name = \"my_model\"):\n",
        "    \"\"\"\n",
        "    주어진 학습 데이터로 모델을 설정하고 최적화하여 가장 좋은 모델을 반환.\n",
        "    \"\"\"\n",
        "    data_seen = copy.deepcopy(data_seen)\n",
        "    data_seen = data_seen.reset_index(drop=True)\n",
        "    model_performance = []\n",
        "    model_list = []\n",
        "\n",
        "    for id in range(11, 11+model_num):  # 앙상블 모델 20개\n",
        "        #id = random.randint(1,100)\n",
        "        reg_test = setup(data=data_seen,\n",
        "                         target=TARGET_COL,\n",
        "                         use_gpu=True,\n",
        "                         fold=3,\n",
        "                         train_size=0.80,\n",
        "                         session_id=id)\n",
        "\n",
        "        # 모델 비교 및 최적화\n",
        "        best_models = compare_models(\n",
        "            sort='rmse',\n",
        "            n_select=1,\n",
        "        )\n",
        "\n",
        "        model_name = best_models.__class__.__name__\n",
        "        print(model_name)\n",
        "\n",
        "        # 모델의 RMSE 추출\n",
        "        model_rmse = pull()[\"RMSE\"].iloc[0]\n",
        "        model_performance.append((best_models, model_rmse))\n",
        "        model_list.append(best_models)\n",
        "\n",
        "    # RMSE 기준으로 정렬\n",
        "    sorted_model_performance = sorted(model_performance, key=lambda x: x[1])\n",
        "\n",
        "    # 정렬된 모델 리스트 (성능이 좋은 순서대로)\n",
        "    model_list_sorted = [model[0] for model in sorted_model_performance]\n",
        "\n",
        "    if top_k is None: # 별도로 갯수 옵션을 안줄시, 모델리스트의 모든 모델을 앙상블에 활용\n",
        "        top_k = len(model_list)\n",
        "\n",
        "    # 모델 블렌딩\n",
        "    result = blend_models(model_list_sorted[:top_k])  #  전체사용\n",
        "    result = finalize_model(result)  # 최종 모델로 고정\n",
        "\n",
        "    if my_model_name:\n",
        "        save_model(model=result,\n",
        "            model_name=my_model_name,\n",
        "            verbose=False)\n",
        "\n",
        "    return result\n",
        "\n",
        "def predict_with_models(model, data_seen, data_unseen):\n",
        "    \"\"\"\n",
        "    주어진 모델들을 사용하여 예측하고, 예측 결과를 반환.\n",
        "    \"\"\"\n",
        "    data_seen = copy.deepcopy(data_seen).reset_index(drop=True)\n",
        "    data_unseen = copy.deepcopy(data_unseen).reset_index(drop=True)\n",
        "\n",
        "    predictions_seen = predict_model(model, data=data_seen)\n",
        "    predictions_seen[\"error_rate\"] = 100 * (predictions_seen[\"prediction_label\"] - predictions_seen[TARGET_COL]) / predictions_seen[TARGET_COL]\n",
        "    seen_avg_error_rate = np.mean(np.abs(np.array(predictions_seen[\"error_rate\"].iloc[:])))\n",
        "\n",
        "    predictions_unseen = predict_model(model, data=data_unseen)\n",
        "    predictions_unseen[\"error_rate\"] = 100 * (predictions_unseen[\"prediction_label\"] - predictions_unseen[TARGET_COL]) / predictions_unseen[TARGET_COL]\n",
        "    unseen_avg_error_rate = np.mean(np.abs(np.array(predictions_unseen[\"error_rate\"].iloc[:])))\n",
        "\n",
        "    return predictions_seen, predictions_unseen, seen_avg_error_rate, unseen_avg_error_rate\n",
        "\n",
        "def split_x_y(data, test_years):\n",
        "    X = data.drop(columns=data.columns[data.columns.str.contains('next')],axis=1)  # 독립 변수만 모음\n",
        "    X.dropna(axis=1, inplace=True) # 모든년도에서 쓸 수 있는 피처만 남기기\n",
        "    y = data[TARGET_COL]  # 종속 변수\n",
        "\n",
        "    X_real = X[X['year']==LIVE_YEAR] # 라이브 데이터는 따로 빼둔다\n",
        "    y_real = y.loc[X_real.index]\n",
        "\n",
        "    X = X[X['year']!=LIVE_YEAR]\n",
        "    y = y.loc[X.index]\n",
        "\n",
        "    X_train, X_test  = X[~X['year'].isin(test_years)], X[X['year'].isin(test_years)]\n",
        "    y_train, y_test  = y[X_train.index], y[X_test.index]\n",
        "\n",
        "    # 인덱스 에러 방지\n",
        "    X_real.reset_index(drop=True,inplace=True)\n",
        "    y_real.reset_index(drop=True,inplace=True)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, X_real, y_real\n",
        "\n",
        "def get_mi_feature_importance(x, y,num_of_features):\n",
        "    x=x.reset_index(drop=True)\n",
        "    y=y.reset_index(drop=True)\n",
        "\n",
        "    # Mutual Information 계산\n",
        "    mi_scores = mutual_info_regression(x, y)\n",
        "\n",
        "    # 중요 Feature만 선택\n",
        "    feature_importances = pd.Series(mi_scores, index=x.columns)\n",
        "    selected_features = feature_importances[feature_importances > feature_importances.mean()].index  # 임계값 설정\n",
        "\n",
        "    # 모델별 중요도 시각화\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    for idx, importance in enumerate(feature_importances.items()):\n",
        "        sorted_idx = np.argsort(importance)[::-1]  # 중요도 내림차순 정렬\n",
        "        axes[idx].barh(x.columns[sorted_idx], importance[sorted_idx], color='skyblue')\n",
        "        axes[idx].set_title(f'Mutual Information Feature Importance')\n",
        "        axes[idx].set_xlabel('Importance')\n",
        "        axes[idx].invert_yaxis()  # 중요도 높은 순서로 표시\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    if num_of_features:\n",
        "        selected_features = selected_features[:num_of_features]\n",
        "\n",
        "    # pd.DataFrame(selected_features).to_csv(\"selected_features.csv\",index=None,encoding='utf-8-sig')\n",
        "    return selected_features"
      ],
      "metadata": {
        "id": "5ctFCVU4AvmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_data_load(num_of_features, test_years, group_idx):\n",
        "    # 데이터 로딩\n",
        "    bef = pd.read_csv(\"배추_transpose_2024.csv\",encoding='utf-8-sig')\n",
        "    aft = pd.read_csv(\"combined_weather_data(preprocessed_weather).csv\",encoding='utf-8-sig')\n",
        "\n",
        "    # drop 2025\n",
        "    bef_from_2006 = bef[(bef['year']<2024)&(bef['year']>=2006)]\n",
        "    aft_from_2006 = aft[(aft['year']<2024)&(aft['year']>=2006)]\n",
        "\n",
        "    aft_from_2006 = aft_from_2006.interpolate(method='values')\n",
        "    # data_origin = preprocess_data(data_origin) # 일부 열이름 변경 (통일)\n",
        "\n",
        "    X_train, X_test, y_train, y_test, X_real, y_real = split_x_y(aft_from_2006, test_years) # bef_from_2006\n",
        "\n",
        "    X_scaled_train, scaler = scale_data(X_train, is_fit=True)\n",
        "    X_scaled_test, scaler = scale_data(X_test, is_fit=False, scaler = scaler)\n",
        "    X_scaled_live, scaler = scale_data(X_real, is_fit=False, scaler = scaler)\n",
        "\n",
        "    # Feature Importance 함수 호출 (2024는 y값이 없어서 제외)\n",
        "    final_features = get_feature_importance(X_scaled_train, y_train, num_of_features)\n",
        "    print(\"\\nFinal Selected Features1:\", final_features)\n",
        "\n",
        "    # selected_features_2 = get_mi_feature_importance(X_scaled_train, y_train, num_of_features)\n",
        "    # print(\"\\nFinal Selected Features2:\", selected_features_2)\n",
        "\n",
        "    #final_features = list(set(selected_features_1)|set(selected_features_2))\n",
        "    #print(\"common final feats : \", final_features)\n",
        "\n",
        "    pd.DataFrame(final_features).to_csv(f\"{MODEL_PATH}/selected_features{MODEL_NUM}({group_idx}).csv\",index=None,encoding='utf-8-sig')\n",
        "\n",
        "    # final_features = ['11월_김치수입','해당년도 11월 배추 경락가','해당년도 12월 배추 경락가','diff_해당년도 5월 배추 경락가_하순-해당년도 5월 배추 경락가_상순','diff_해당년도 7월 배추 경락가_하순-해당년도 7월 배추 경락가_중순','diff_해당년도 8월 배추 경락가_중순-해당년도 8월 배추 경락가_상순','diff_해당년도 9월 배추 경락가_상순-해당년도 8월 배추 경락가_상순','diff_해당년도 9월 배추 경락가_하순-해당년도 7월 배추 경락가_하순','diff_해당년도 10월 배추 경락가_하순-해당년도 10월 배추 경락가_상순','diff_해당년도 10월 배추 경락가_상순-해당년도 6월 배추 경락가_상순']\n",
        "\n",
        "    X_scaled_train.index, X_scaled_test.index = X_train.index , X_test.index\n",
        "    X_train, X_test, X_scaled_live = X_scaled_train[final_features], X_scaled_test[final_features], X_scaled_live[final_features]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, X_scaled_live, y_real\n",
        "\n",
        "import joblib\n",
        "\n",
        "def main(test_years, group_idx):\n",
        "    num_of_features = 10\n",
        "    X_train, X_test, y_train, y_test, X_live, y_fakelive = my_data_load(num_of_features, test_years, group_idx)\n",
        "\n",
        "    train_data = pd.concat([X_train,y_train],axis=1)\n",
        "    test_data = pd.concat([X_test,y_test],axis=1)\n",
        "    live_data = pd.concat([X_live, y_fakelive],axis=1)\n",
        "\n",
        "    live_data = live_data.dropna(subset=['year']) # 2025등 널값제거\n",
        "    train_for_live = pd.concat([train_data,test_data],axis=0)\n",
        "\n",
        "    print(train_data.columns)\n",
        "\n",
        "    # # 모델 학습 및 최적화\n",
        "    model_name = MODEL_PATH + f\"_{group_idx}\"\n",
        "    base_model = train_and_optimize_models(train_data, 15, 5, model_name) # 데이터, 만들어낼모델수(15), 앙상블할 top-k모델수(5), 모델이름\n",
        "\n",
        "    # # 모델 로딩 및 기본 설정\n",
        "    base_model = joblib.load(model_name + \".pkl\")\n",
        "\n",
        "    # 예측 및 결과\n",
        "    predictions_train, predictions_test, train_avg_error_rate, test_avg_error_rate = predict_with_models(base_model, train_data, test_data)\n",
        "\n",
        "    print(f\"TEST YEARS: {test_years}\")\n",
        "    print(f\"Train Average Error Rate: {train_avg_error_rate:.2f}%\")\n",
        "    print(f\"Test({test_years}) Average Error Rate: {test_avg_error_rate:.2f}%\")\n",
        "\n",
        "    predictions_live_train, predictions_live, train_for_live_avg_error_rate, live_avg_error_rate = predict_with_models(base_model, train_for_live, live_data)\n",
        "    print(f\"LIVE YEAR: {LIVE_YEAR}\")\n",
        "    print(f\"Train for live Average Error Rate: {train_for_live_avg_error_rate:.2f}%\")\n",
        "    print(f\"Live({LIVE_YEAR}) Average Error Rate: {live_avg_error_rate:.2f}%\")\n",
        "    print(f\"predicted Live({LIVE_YEAR}) : {predictions_live}\")"
      ],
      "metadata": {
        "id": "MaWn4t8ZAveo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "\n",
        "# MODEL_NUM = 1\n",
        "# MODEL_PATH = '/content/' # colab : /content/\n",
        "\n",
        "# LIVE_YEAR = 2023\n",
        "# test_years = [2021,2022]\n",
        "\n",
        "# TARGET_COL = 'next_3_price'\n",
        "\n",
        "# start_time = time.time()\n",
        "# main(test_years, 7)\n",
        "# print(f\"Execution Time: {time.time() - start_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "e8xjOU1J4YTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 처리"
      ],
      "metadata": {
        "id": "wpxq28clKWD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 외부 공실률 통합 및 정제"
      ],
      "metadata": {
        "id": "4wHsw4IWKX25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# 정규표현식 패턴\n",
        "pattern = r\"[^공실률가-힣]*([가-힣]+)[^공실률가-힣]*\"\n",
        "\n",
        "def preprocess_vcrate_df(df):\n",
        "  preprocessed_df = df.copy()\n",
        "  preprocessed_df = pd.melt(df, id_vars = ['자료시점','공실률종류'])\n",
        "  preprocessed_df['년도'] = preprocessed_df['자료시점'].apply(lambda x : int(x[:4]) if '분기' in x else np.nan)\n",
        "  preprocessed_df['분기'] = preprocessed_df['자료시점'].apply(lambda x : int(x[-3:-2]) if '분기' in x else np.nan)\n",
        "  preprocessed_df = preprocessed_df.dropna(subset=['년도'],axis=0)\n",
        "  preprocessed_df['지역'] = preprocessed_df['variable'].apply(lambda x : re.findall(pattern, x)[0] if len(re.findall(pattern, x))>0 else x)\n",
        "  preprocessed_df = preprocessed_df[(preprocessed_df['variable']!='No')&(preprocessed_df['variable']!='전국')] # 불필요한 칼럼 제거\n",
        "  return preprocessed_df"
      ],
      "metadata": {
        "id": "xX7V_qTFFA3Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "center = pd.read_csv(\"center.csv\")\n",
        "\n",
        "# zip 파일 경로 설정\n",
        "zip_path = '/content/vcrate_outfiles.zip'\n",
        "\n",
        "all_data = []\n",
        "\n",
        "# zip 파일을 열기\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    # zip 파일 내의 모든 파일 리스트\n",
        "    file_list = zip_ref.namelist()\n",
        "\n",
        "    # CSV 파일만 필터링\n",
        "    csv_files = [f for f in file_list if f.endswith('.csv')]\n",
        "\n",
        "    # 여러 CSV 파일을 읽어서 하나의 데이터프레임으로 결합\n",
        "    file_names = [str(file).split(\"_\")[-1].split(\".\")[0] for file in csv_files]\n",
        "\n",
        "    for idx, file in enumerate(csv_files):\n",
        "      df = pd.read_csv(zip_ref.open(file), encoding='euc-kr')\n",
        "      df['공실률종류'] = file_names[idx]\n",
        "      all_data.append(preprocess_vcrate_df(df))\n",
        "\n",
        "all_data = pd.concat(all_data, ignore_index=True)\n",
        "# 데이터 확인\n",
        "all_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "avu-n-8WDN-N",
        "outputId": "0221039b-5f30-4b90-8560-57c86aaa8b9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'center.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-195fd4b954a4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"center.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# zip 파일 경로 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'center.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data.to_csv(\"전국지역별_년도별분기별_건물종류별_공실률.csv\",encoding='euc-kr',index=None)"
      ],
      "metadata": {
        "id": "Fj38rvj0HW0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 각종 외부 경제 지표"
      ],
      "metadata": {
        "id": "ooSrzYNXKjTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_economy_df(df):\n",
        "    import numpy as np\n",
        "    import re\n",
        "    import pandas as pd\n",
        "\n",
        "    pattern = r'실적|전망'\n",
        "    preprocessed_df = df.copy()\n",
        "    preprocessed_df = pd.melt(df, id_vars=['시점', '업종코드별','BSI코드별'])\n",
        "\n",
        "    preprocessed_df['년도'] = preprocessed_df['시점'].apply(lambda x: int(x[:4]) if '월' in x else np.nan)\n",
        "    preprocessed_df['월'] = preprocessed_df['시점'].apply(lambda x: int(x[5:7]) if '월' in x else np.nan)\n",
        "    preprocessed_df = preprocessed_df.dropna(subset=['년도'])\n",
        "\n",
        "    preprocessed_df['종류'] = preprocessed_df['variable'].apply(lambda x: re.findall(pattern, x)[0] if re.findall(pattern, x) else x)\n",
        "\n",
        "    # BSI 종류 정보만 보존\n",
        "    preprocessed_df['BSI코드별'] = preprocessed_df['BSI코드별'].apply(lambda x: ' '.join(re.findall(r'[가-힣]+', x)))\n",
        "    # 불필요 칼럼 제거\n",
        "    preprocessed_df.drop(columns=['variable'], inplace=True)\n",
        "\n",
        "    # 🚀 변경: stack() 없이 수치형 값만 필터링\n",
        "    preprocessed_df['value'] = pd.to_numeric(preprocessed_df['value'], errors='coerce')\n",
        "    df_numeric = preprocessed_df.dropna(subset=['value'])\n",
        "\n",
        "    return df_numeric"
      ],
      "metadata": {
        "id": "9cPAeR8xWsnL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip 파일 경로 설정\n",
        "zip_path_economy = '/content/업종별_기업경기실사지수.zip'\n",
        "\n",
        "all_ecos = []\n",
        "\n",
        "# zip 파일을 열기\n",
        "with zipfile.ZipFile(zip_path_economy, 'r') as zip_ref:\n",
        "    # zip 파일 내의 모든 파일 리스트\n",
        "    file_list = zip_ref.namelist()\n",
        "\n",
        "    # CSV 파일만 필터링\n",
        "    csv_files = [f for f in file_list if f.endswith('.csv')]\n",
        "\n",
        "    # 여러 CSV 파일을 읽어서 하나의 데이터프레임으로 결합\n",
        "    # file_names = [str(file).split(\"_\")[-1].split(\".\")[0] for file in csv_files]\n",
        "\n",
        "    for idx, file in enumerate(csv_files):\n",
        "      df = pd.read_csv(zip_ref.open(file), encoding='euc-kr')\n",
        "      all_ecos.append(preprocess_economy_df(df))\n",
        "\n",
        "all_ecos = pd.concat(all_ecos, ignore_index=True)\n",
        "# 데이터 확인\n",
        "all_ecos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ojZs7T7BKjM3",
        "outputId": "f9c9dcb8-7814-4471-9231-ff11c71a7a51"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               시점  업종코드별  BSI코드별  value    년도   월  종류\n",
              "0       2003.01 월  전 산 업    업황실적   82.0  2003   1  실적\n",
              "1       2003.02 월  전 산 업    업황실적   73.0  2003   2  실적\n",
              "2       2003.03 월  전 산 업    업황실적   71.0  2003   3  실적\n",
              "3       2003.04 월  전 산 업    업황실적   76.0  2003   4  실적\n",
              "4       2003.05 월  전 산 업    업황실적   74.0  2003   5  실적\n",
              "...           ...    ...     ...    ...   ...  ..  ..\n",
              "272955  2024.10 월   내수기업  인력사정전망   89.0  2024  10  전망\n",
              "272956  2024.11 월   내수기업  인력사정전망   90.0  2024  11  전망\n",
              "272957  2024.12 월   내수기업  인력사정전망   91.0  2024  12  전망\n",
              "272958  2025.01 월   내수기업  인력사정전망   93.0  2025   1  전망\n",
              "272959  2025.02 월   내수기업  인력사정전망   92.0  2025   2  전망\n",
              "\n",
              "[272960 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b88c4ec1-2ad1-4383-9471-753018217997\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>시점</th>\n",
              "      <th>업종코드별</th>\n",
              "      <th>BSI코드별</th>\n",
              "      <th>value</th>\n",
              "      <th>년도</th>\n",
              "      <th>월</th>\n",
              "      <th>종류</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2003.01 월</td>\n",
              "      <td>전 산 업</td>\n",
              "      <td>업황실적</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2003</td>\n",
              "      <td>1</td>\n",
              "      <td>실적</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2003.02 월</td>\n",
              "      <td>전 산 업</td>\n",
              "      <td>업황실적</td>\n",
              "      <td>73.0</td>\n",
              "      <td>2003</td>\n",
              "      <td>2</td>\n",
              "      <td>실적</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2003.03 월</td>\n",
              "      <td>전 산 업</td>\n",
              "      <td>업황실적</td>\n",
              "      <td>71.0</td>\n",
              "      <td>2003</td>\n",
              "      <td>3</td>\n",
              "      <td>실적</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003.04 월</td>\n",
              "      <td>전 산 업</td>\n",
              "      <td>업황실적</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2003</td>\n",
              "      <td>4</td>\n",
              "      <td>실적</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2003.05 월</td>\n",
              "      <td>전 산 업</td>\n",
              "      <td>업황실적</td>\n",
              "      <td>74.0</td>\n",
              "      <td>2003</td>\n",
              "      <td>5</td>\n",
              "      <td>실적</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272955</th>\n",
              "      <td>2024.10 월</td>\n",
              "      <td>내수기업</td>\n",
              "      <td>인력사정전망</td>\n",
              "      <td>89.0</td>\n",
              "      <td>2024</td>\n",
              "      <td>10</td>\n",
              "      <td>전망</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272956</th>\n",
              "      <td>2024.11 월</td>\n",
              "      <td>내수기업</td>\n",
              "      <td>인력사정전망</td>\n",
              "      <td>90.0</td>\n",
              "      <td>2024</td>\n",
              "      <td>11</td>\n",
              "      <td>전망</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272957</th>\n",
              "      <td>2024.12 월</td>\n",
              "      <td>내수기업</td>\n",
              "      <td>인력사정전망</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2024</td>\n",
              "      <td>12</td>\n",
              "      <td>전망</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272958</th>\n",
              "      <td>2025.01 월</td>\n",
              "      <td>내수기업</td>\n",
              "      <td>인력사정전망</td>\n",
              "      <td>93.0</td>\n",
              "      <td>2025</td>\n",
              "      <td>1</td>\n",
              "      <td>전망</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272959</th>\n",
              "      <td>2025.02 월</td>\n",
              "      <td>내수기업</td>\n",
              "      <td>인력사정전망</td>\n",
              "      <td>92.0</td>\n",
              "      <td>2025</td>\n",
              "      <td>2</td>\n",
              "      <td>전망</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>272960 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b88c4ec1-2ad1-4383-9471-753018217997')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b88c4ec1-2ad1-4383-9471-753018217997 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b88c4ec1-2ad1-4383-9471-753018217997');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-176e71c6-0879-4bf9-89a2-891156067765\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-176e71c6-0879-4bf9-89a2-891156067765')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-176e71c6-0879-4bf9-89a2-891156067765 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3d24e8bb-0923-45d1-9dee-5a112029e2ea\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('all_ecos')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3d24e8bb-0923-45d1-9dee-5a112029e2ea button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('all_ecos');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "all_ecos"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_ecos.to_csv(\"년도별월별_전국_업종별_기업경기지수.csv\",encoding='euc-kr',index=None)"
      ],
      "metadata": {
        "id": "pBRJbpZjiHkP"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}